{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4facede9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4facede9",
        "outputId": "2e9e5405-c0c4-4f6f-b97b-ac43f34060cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.2.7 (from langchain)\n",
            "  Downloading langchain_core-1.2.8-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.6)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (2.5.0)\n",
            "Downloading langchain_groq-1.1.2-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.8-py3-none-any.whl (495 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m495.8/495.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-core, langchain-groq\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.7\n",
            "    Uninstalling langchain-core-1.2.7:\n",
            "      Successfully uninstalled langchain-core-1.2.7\n",
            "Successfully installed groq-0.37.1 langchain-core-1.2.8 langchain-groq-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8718cb7f",
      "metadata": {
        "id": "8718cb7f"
      },
      "outputs": [],
      "source": [
        "GROQ_API_KEY=\"Your api key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e38e873e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e38e873e",
        "outputId": "e86d3314-70bb-42ae-afd4-faf863123553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ AI Question Answering Chatbot (type 'exit' to quit)\n",
            "\n",
            "You: what is ai \n",
            "Bot: **Artificial Intelligence (AI)** is a branch of computer science that aims to create machines and software capable of performing tasks that normally require human intelligence. These tasks include learning, reasoning, problem‚Äësolving, perception, language understanding, and decision‚Äëmaking.\n",
            "\n",
            "---\n",
            "\n",
            "## Core Ideas\n",
            "\n",
            "| Concept | What it means |\n",
            "|---------|---------------|\n",
            "| **Machine Learning (ML)** | Algorithms that improve automatically through experience (e.g., recognizing images after being shown many examples). |\n",
            "| **Deep Learning** | A subset of ML that uses multi‚Äëlayered neural networks to model complex patterns (e.g., speech‚Äëto‚Äëtext, image generation). |\n",
            "| **Natural Language Processing (NLP)** | Techniques for understanding and generating human language (e.g., chatbots, translation). |\n",
            "| **Computer Vision** | Enabling computers to interpret visual information (e.g., facial recognition, autonomous driving). |\n",
            "| **Planning & Reasoning** | Systems that can devise sequences of actions to achieve goals (e.g., game‚Äëplaying AI, robotics). |\n",
            "| **Reinforcement Learning** | Agents learn by trial‚Äëand‚Äëerror, receiving rewards for desirable actions (e.g., AlphaGo, robotics control). |\n",
            "\n",
            "---\n",
            "\n",
            "## Types of AI (by capability)\n",
            "\n",
            "| Category | Description | Example |\n",
            "|----------|-------------|---------|\n",
            "| **Narrow (Weak) AI** | Designed for a specific task; does not possess general reasoning. | Voice assistants (Siri, Alexa), recommendation engines. |\n",
            "| **General (Strong) AI** | Hypothetical AI that can understand, learn, and apply knowledge across any domain like a human. | Not yet realized; a major research goal. |\n",
            "| **Superintelligent AI** | AI that surpasses human intelligence in all areas. | Purely speculative at present. |\n",
            "\n",
            "---\n",
            "\n",
            "## Types of AI (by functionality)\n",
            "\n",
            "| Functional Category | Typical Use Cases |\n",
            "|---------------------|-------------------|\n",
            "| **Reactive Machines** | Simple stimulus‚Äëresponse (e.g., IBM Deep Blue chess). |\n",
            "| **Limited Memory** | Uses past data for decisions (e.g., self‚Äëdriving cars). |\n",
            "| **Theory of Mind** | Future systems that understand emotions, beliefs (research stage). |\n",
            "| **Self‚ÄëAware** | Machines with consciousness (theoretical). |\n",
            "\n",
            "---\n",
            "\n",
            "## Brief History Highlights\n",
            "\n",
            "| Era | Milestones |\n",
            "|-----|------------|\n",
            "| **1950s‚Äì60s** | Alan Turing‚Äôs ‚ÄúComputing Machinery and Intelligence‚Äù (1950); Dartmouth workshop (1956) coined ‚ÄúAI‚Äù. |\n",
            "| **1970s‚Äì80s** | Expert systems (e.g., MYCIN) dominate commercial AI. |\n",
            "| **1990s** | Machine learning gains traction; IBM‚Äôs Deep Blue defeats world chess champion (1997). |\n",
            "| **2000s** | Big data & faster hardware enable statistical ML; early deep learning breakthroughs. |\n",
            "| **2010s** | Deep neural nets excel (ImageNet 2012); AI in speech, vision, translation; AlphaGo beats Go champion (2016). |\n",
            "| **2020s** | Large language models (GPT‚Äë3/4, PaLM, LLaMA) demonstrate impressive text generation and reasoning; AI integrated into everyday products. |\n",
            "\n",
            "---\n",
            "\n",
            "## Common Applications\n",
            "\n",
            "- **Healthcare:** disease diagnosis, drug discovery, medical imaging analysis.  \n",
            "- **Finance:** fraud detection, algorithmic trading, credit scoring.  \n",
            "- **Transportation:** autonomous vehicles, traffic optimization.  \n",
            "- **Customer Service:** chatbots, sentiment analysis.  \n",
            "- **Creative Arts:** image/video generation, music composition, code assistance.  \n",
            "- **Manufacturing:** predictive maintenance, quality inspection, robotics.  \n",
            "\n",
            "---\n",
            "\n",
            "## How AI Works (simplified)\n",
            "\n",
            "1. **Data Collection** ‚Äì Gather labeled or unlabeled data (images, text, sensor readings).  \n",
            "2. **Pre‚Äëprocessing** ‚Äì Clean, normalize, and transform data into a usable format.  \n",
            "3. **Model Selection** ‚Äì Choose an algorithm (e.g., decision tree, convolutional neural network).  \n",
            "4. **Training** ‚Äì Adjust model parameters to minimize error on the training data.  \n",
            "5. **Evaluation** ‚Äì Test on unseen data to gauge performance (accuracy, F1‚Äëscore, etc.).  \n",
            "6. **Deployment** ‚Äì Integrate the model into an application or service.  \n",
            "7. **Monitoring & Updating** ‚Äì Continuously track performance and retrain as needed.\n",
            "\n",
            "---\n",
            "\n",
            "## Key Considerations & Challenges\n",
            "\n",
            "- **Bias & Fairness:** Models can inherit biases present in training data.  \n",
            "- **Explainability:** Understanding why an AI makes a decision is crucial for trust.  \n",
            "- **Privacy & Security:** Handling sensitive data responsibly.  \n",
            "- **Regulation:** Emerging laws (e.g., EU AI Act) aim to govern AI use.  \n",
            "- **Energy Consumption:** Large models require significant compute resources.\n",
            "\n",
            "---\n",
            "\n",
            "### Quick Takeaway\n",
            "\n",
            "AI is the science of building systems that can **learn from data**, **reason**, and **act** in ways that mimic or surpass human capabilities. While today‚Äôs AI is largely **narrow** and excels in specific tasks, research continues toward more general, adaptable intelligence. Its impact spans virtually every industry, reshaping how we work, communicate, and solve problems.\n",
            "You: what is difff between deep learnign and machine learnig'\n",
            "Bot: **Short answer:**  \n",
            "All deep‚Äëlearning (DL) methods are a subset of machine‚Äëlearning (ML), but not all ML methods are deep learning. The key differences lie in how the models are built, the amount of feature engineering required, and the types of problems they excel at.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. What is Machine Learning (ML)?\n",
            "\n",
            "- **Definition:** A broad field of algorithms that enable computers to learn patterns from data and make predictions or decisions without being explicitly programmed for each task.\n",
            "- **Typical workflow:**  \n",
            "  1. **Collect data** ‚Üí  \n",
            "  2. **Pre‚Äëprocess & clean** ‚Üí  \n",
            "  3. **Feature engineering** (hand‚Äëcrafting informative variables) ‚Üí  \n",
            "  4. **Choose a model** (e.g., linear regression, decision trees, SVM, k‚ÄëNN) ‚Üí  \n",
            "  5. **Train & validate** ‚Üí  \n",
            "  6. **Deploy.**\n",
            "- **Common algorithms:**  \n",
            "  - Linear / logistic regression  \n",
            "  - Decision trees & random forests  \n",
            "  - Support Vector Machines (SVM)  \n",
            "  - k‚ÄëNearest Neighbors (k‚ÄëNN)  \n",
            "  - Gradient boosting (XGBoost, LightGBM)  \n",
            "- **Strengths:**  \n",
            "  - Works well on small‚Äëto‚Äëmedium sized datasets.  \n",
            "  - Interpretable (e.g., coefficients in linear models, feature importance in trees).  \n",
            "  - Faster to train and requires less computational power.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. What is Deep Learning (DL)?\n",
            "\n",
            "- **Definition:** A sub‚Äëfield of ML that uses **artificial neural networks with many layers** (hence ‚Äúdeep‚Äù) to automatically learn hierarchical representations of data.\n",
            "- **Typical workflow:**  \n",
            "  1. **Collect data** ‚Üí  \n",
            "  2. **Minimal preprocessing** (often just scaling/normalization) ‚Üí  \n",
            "  3. **Feed raw data into a neural network** ‚Üí  \n",
            "  4. **Network learns both features and the predictor** during training ‚Üí  \n",
            "  5. **Validate & fine‚Äëtune** (architecture, hyper‚Äëparameters) ‚Üí  \n",
            "  6. **Deploy.**\n",
            "- **Common architectures:**  \n",
            "  - **Feed‚Äëforward (MLP)** ‚Äì basic dense layers.  \n",
            "  - **Convolutional Neural Networks (CNNs)** ‚Äì for images, video, spatial data.  \n",
            "  - **Recurrent Neural Networks (RNNs) / LSTMs / GRUs** ‚Äì for sequences, text, time series.  \n",
            "  - **Transformers** ‚Äì state‚Äëof‚Äëthe‚Äëart for language, vision, multimodal tasks.  \n",
            "  - **Autoencoders, GANs, Diffusion models** ‚Äì for generative tasks.\n",
            "- **Strengths:**  \n",
            "  - **Automatic feature learning** ‚Äì the network discovers useful representations on its own.  \n",
            "  - **Scales with data** ‚Äì performance often improves dramatically with more labeled data and larger models.  \n",
            "  - **State‚Äëof‚Äëthe‚Äëart performance** on image classification, speech recognition, natural‚Äëlanguage processing, game playing, etc.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. Key Differences at a Glance\n",
            "\n",
            "| Aspect | Traditional ML | Deep Learning |\n",
            "|--------|----------------|----------------|\n",
            "| **Model family** | Linear models, trees, SVMs, etc. | Multi‚Äëlayer neural networks |\n",
            "| **Feature engineering** | Usually required (domain knowledge) | Mostly automatic (raw data can be used) |\n",
            "| **Data size needed** | Works well with tens to thousands of samples | Thrives on tens of thousands to millions of samples |\n",
            "| **Computational demand** | Light‚Äëto‚Äëmoderate (CPU often enough) | Heavy (GPU/TPU, large memory) |\n",
            "| **Interpretability** | Generally higher (e.g., coefficients, feature importance) | Lower; often considered a ‚Äúblack box‚Äù (though tools like SHAP, LIME help) |\n",
            "| **Typical use cases** | Fraud detection, churn prediction, simple recommendation, tabular data | Image/video analysis, speech/audio, language translation, complex pattern recognition |\n",
            "| **Training time** | Seconds to minutes | Minutes to weeks, depending on model size and data |\n",
            "| **Hyper‚Äëparameter tuning** | Fewer, often easier (e.g., depth of tree, regularization) | Many (layers, neurons, learning rate schedules, dropout, etc.) |\n",
            "\n",
            "---\n",
            "\n",
            "## 4. When to Choose Which?\n",
            "\n",
            "| Situation | Prefer ML | Prefer DL |\n",
            "|-----------|-----------|-----------|\n",
            "| **Tabular data with limited samples** | ‚úîÔ∏è (e.g., gradient boosting) | ‚ùå (needs huge data) |\n",
            "| **Image classification with >10k labeled pictures** | ‚ùå (hand‚Äëcrafted features are hard) | ‚úîÔ∏è (CNNs) |\n",
            "| **Speech‚Äëto‚Äëtext or voice assistants** | ‚ùå | ‚úîÔ∏è (RNNs/Transformers) |\n",
            "| **Real‚Äëtime inference on edge devices with strict latency** | ‚úîÔ∏è (lightweight models) | ‚úîÔ∏è if you can compress (e.g., quantized CNN) |\n",
            "| **Need for model explainability** | ‚úîÔ∏è (e.g., decision trees) | ‚ùå (use post‚Äëhoc explainers) |\n",
            "| **Research prototype where you have massive GPU clusters** | ‚ùå | ‚úîÔ∏è (large transformer or diffusion model) |\n",
            "\n",
            "---\n",
            "\n",
            "## 5. A Simple Analogy\n",
            "\n",
            "- **Machine Learning** is like giving a student a **hand‚Äëcrafted study guide** (features) and teaching them a specific algorithm to solve a problem.\n",
            "- **Deep Learning** is like giving the student the **raw textbook** and letting them discover the important concepts themselves through many layers of understanding.\n",
            "\n",
            "---\n",
            "\n",
            "## 6. Quick Code Sketch (Python)\n",
            "\n",
            "```python\n",
            "# Traditional ML (Random Forest on tabular data)\n",
            "from sklearn.ensemble import RandomForestClassifier\n",
            "model_ml = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
            "model_ml.fit(X_train, y_train)\n",
            "\n",
            "# Deep Learning (CNN on images)\n",
            "import tensorflow as tf\n",
            "model_dl = tf.keras.Sequential([\n",
            "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(64,64,3)),\n",
            "    tf.keras.layers.MaxPooling2D(),\n",
            "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
            "    tf.keras.layers.MaxPooling2D(),\n",
            "    tf.keras.layers.Flatten(),\n",
            "    tf.keras.layers.Dense(128, activation='relu'),\n",
            "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
            "])\n",
            "model_dl.compile(optimizer='adam',\n",
            "                 loss='sparse_categorical_crossentropy',\n",
            "                 metrics=['accuracy'])\n",
            "model_dl.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
            "```\n",
            "\n",
            "The first snippet needs engineered features (`X_train`). The second works directly on raw pixel arrays.\n",
            "\n",
            "---\n",
            "\n",
            "## 7. Bottom Line\n",
            "\n",
            "- **Deep learning = a powerful, data‚Äëhungry subset of machine learning that learns features automatically via deep neural networks.**\n",
            "- **Machine learning = the broader toolbox that includes many algorithms, often more suitable for smaller datasets, tabular data, and scenarios where interpretability and speed are critical.**\n",
            "\n",
            "Choose the approach that matches your data volume, problem type, computational resources, and need for explainability.\n",
            "You: exit\n",
            "Bot: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "print(\"ü§ñ AI Question Answering Chatbot (type 'exit' to quit)\\n\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"You: \")\n",
        "\n",
        "    if user_question.lower() == \"exit\":\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"openai/gpt-oss-120b\",   # Pre-trained LLM\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful question answering assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": user_question}\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content\n",
        "    print(\"Bot:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdfdc70b",
      "metadata": {
        "id": "bdfdc70b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}